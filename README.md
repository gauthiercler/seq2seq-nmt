## Neural Machine Translation with seq2seq architecture



#### TODO

- [ ] Beam Search
- [X] Curriculum Teacher Forcing
- [ ] Scheduled sampling
- [ ] use LSTM
- [ ] Attention
- [X] Dropout
- [ ] Save model state at defined intervals
- [ ] Use trained Embeddings (GloVe, Doc2Vec...)
- [ ] Streamlit playground with trained models (or upload model)
- [ ] Multiple language pairs support
- [X] train, dev, test sets
- [ ] buckets
- [ ] backward feeding
